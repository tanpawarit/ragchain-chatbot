{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984a9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install langchain langchain-openai langchain-community faiss-cpu openai tiktoken trafilatura playwright nest_asyncio langchain_experimental\n",
    "# !uv add langchain langchain-openai langchain-community faiss-cpu openai tiktoken trafilatura playwright nest_asyncio langchain_experimental\n",
    "# !playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11f0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_config\n",
    "\n",
    "config = get_config() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e22cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î LLM ‡πÄ‡∏õ‡πá‡∏ô Typhoon\u001b[39;00m\n\u001b[32m     14\u001b[39m typhoon_llm = ChatOpenAI(\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     api_key=\u001b[43mconfig\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtyphoon\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     16\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.opentyphoon.ai/v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mtyphoon-v2.1-12b-instruct\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     temperature=\u001b[32m0\u001b[39m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m embeddings = OpenAIEmbeddings(\n\u001b[32m     22\u001b[39m     api_key=config[\u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     23\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m     ) \n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    " \n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î LLM ‡πÄ‡∏õ‡πá‡∏ô Typhoon\n",
    "typhoon_llm = ChatOpenAI(\n",
    "    api_key=config['typhoon']['token'],\n",
    "    base_url=\"https://api.opentyphoon.ai/v1\",\n",
    "    model=\"typhoon-v2.1-12b-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=config['openai']['token'],\n",
    "    model=\"text-embedding-3-small\"\n",
    "    ) \n",
    "\n",
    "\n",
    "import os\n",
    "import time \n",
    "# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Path ---\n",
    "DATA_FOLDER = \"data/raw\"  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏≤‡∏Å \"product_data\" ‡πÄ‡∏õ‡πá‡∏ô \"data/raw\"\n",
    "FILE_NAMES = [\"workshop.txt\", \"rerun.txt\", \"overall.txt\"]\n",
    "FAISS_INDEX_PATH = \"artifacts/faiss_product_index\"  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Index\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á DATA_PATHS ‡∏à‡∏≤‡∏Å DATA_FOLDER ‡πÅ‡∏•‡∏∞ FILE_NAMES\n",
    "DATA_PATHS = [os.path.join(DATA_FOLDER, fname) for fname in FILE_NAMES]\n",
    "\n",
    "# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î/‡∏™‡∏£‡πâ‡∏≤‡∏á Index ---\n",
    "index_file = os.path.join(FAISS_INDEX_PATH, \"index.faiss\")\n",
    "\n",
    "if os.path.exists(index_file):\n",
    "    print(f\"\\n‚úÖ ‡∏û‡∏ö Index ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å '{FAISS_INDEX_PATH}'...\")\n",
    "    start_time = time.time()\n",
    "    vectorstore = FAISS.load_local(\n",
    "        FAISS_INDEX_PATH,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Index ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "else:\n",
    "    print(f\"\\nüü° ‡πÑ‡∏°‡πà‡∏û‡∏ö Index, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {', '.join(FILE_NAMES)}\")\n",
    "    start_time = time.time()\n",
    "    all_docs = []\n",
    "    # Loop ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ DATA_PATHS ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô\n",
    "    for path in DATA_PATHS:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"‚ÄºÔ∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà '{path}' ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå\")\n",
    "            continue\n",
    "        print(f\"  - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {path}\")\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "        docs_from_file = loader.load()\n",
    "        all_docs.extend(docs_from_file)\n",
    "\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "    if not all_docs:\n",
    "        print(\"\\n‚ÄºÔ∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢\")\n",
    "        print(\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_docs)} document(s) ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n",
    "\n",
    "        text_splitter = SemanticChunker(\n",
    "            embeddings=embeddings,\n",
    "            breakpoint_threshold_type=\"percentile\"  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö ‡πÄ‡∏ä‡πà‡∏ô \"standard_deviation\", \"interquartile\", \"gradient\"\n",
    "        )\n",
    "        splits = text_splitter.split_documents(all_docs)\n",
    "        print(f\"‚úÖ ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô {len(splits)} chunks\")\n",
    "\n",
    "        print(\"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡∏î‡πâ‡∏ß‡∏¢ FAISS (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà)...\")\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "        vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "        end_time = time.time()\n",
    "        print(f\"üíæ Index ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà '{FAISS_INDEX_PATH}' ‡πÉ‡∏ô {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á retriever ‡∏à‡∏≤‡∏Å vectorstore (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç NameError)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏°‡∏≤\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8dbf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö (RAG) ---\n",
      "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡∏°‡∏µ‡πÄ‡∏ß‡∏¥‡∏Ñ‡∏ä‡πâ‡∏≠‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ç‡∏≤‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏á\n",
      "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà SCB 10X ‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "\n",
      "‡∏ú‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡∏ä‡πá‡∏≠‡∏õ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡∏ä‡πá‡∏≠‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö:\n",
      "\n",
      "*   **Online Workshops \"‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÄ‡∏ó‡∏£‡∏î‡∏î‡πâ‡∏ß‡∏¢ Quant Data\":** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡∏ä‡πá‡∏≠‡∏õ‡πÉ‡∏î ‡πÜ ‡∏£‡∏≤‡∏Ñ‡∏≤ 3,599 ‡∏ö‡∏≤‡∏ó ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "    *   RERUN ‡∏ó‡∏∏‡∏Å Session ‡∏ó‡∏±‡πâ‡∏á Stage 1 & 2 (‡∏£‡∏ß‡∏° 11 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)\n",
      "    *   RERUN Crypto Quant Trading (‡∏£‡∏ß‡∏° 7 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)\n",
      "    *   ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏î‡∏π Quant Tool ‡∏Ç‡∏≠‡∏á Investic Analytics Studio ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô\n",
      "*   **Rerun Quant Offside 3x:** ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Market Breadth ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Filter ‡∏ï‡∏•‡∏≤‡∏î, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡∏•‡∏≤‡∏î, ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏´‡∏∏‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Fundamental Analysis ‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏≠‡∏µ‡∏Å‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "*   **Mastering Crypto Trading: Essential Indicators, Tools, and Yield Strategies:** ‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏•‡∏≤‡∏î‡∏Ñ‡∏£‡∏¥‡∏õ‡πÇ‡∏ï‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö, ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å, ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô (Yield) ‡∏ó‡∏µ‡πà‡∏á‡∏≠‡∏Å‡πÄ‡∏á‡∏¢‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ñ‡∏∑‡∏≠‡∏Ñ‡∏£‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•\n",
      "*   **Crypto Quant Trading:** ‡πÇ‡∏ã‡∏ô‡∏à‡∏±‡∏î‡πÅ‡∏™‡∏î‡∏á‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏° ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö Quant Trading ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏ä‡πá‡∏≠‡∏õ‡∏à‡∏≤‡∏Å Binance TH ‡πÅ‡∏•‡∏∞ Cryptomind & Merkle Capital\n",
      "\n",
      "**‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠:** ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡∏ä‡πá‡∏≠‡∏õ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "\n",
      "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡∏ä‡πá‡∏≠‡∏õ‡πÉ‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏à‡πâ‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏£‡∏±‡∏ö\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "### ROLE ###\n",
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Sales & Support Specialist\n",
    "\n",
    "### OBJECTIVE ###\n",
    "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (Conversion) ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á, ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå, ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à ‡πÇ‡∏î‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô KNOWLEDGE BASE ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "### TONE OF VOICE ###\n",
    "- Professional (‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û)\n",
    "- Helpful (‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠)\n",
    "- Persuasive (‡πÇ‡∏ô‡πâ‡∏°‡∏ô‡πâ‡∏≤‡∏ß)\n",
    "- Confident (‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à)\n",
    "- Thai language, formal \"‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞\" tone.\n",
    "\n",
    "### WORKFLOW ###\n",
    "1.  **Acknowledge and Understand:** ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÉ‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "2.  **Extract & Reframe:** ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å KNOWLEDGE BASE ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á \"‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå\" ‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö\n",
    "3.  **Address Concerns & Compare:** ‡∏´‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÄ‡∏£‡∏≤\n",
    "4.  **Suggest & Guide (Call-to-Action):** ‡πÄ‡∏™‡∏ô‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ã‡∏∑‡πâ‡∏≠, ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô, ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô\n",
    "\n",
    "### RULES ###\n",
    "- DO NOT invent information not present in the KNOWLEDGE BASE.\n",
    "- If information is missing, politely state that you need to check with a specialist and offer to assist with other questions.\n",
    "- Always end the conversation with a call to action or an offer for further help.\n",
    "\n",
    "---\n",
    "### KNOWLEDGE BASE (Context) ###\n",
    "{context}\n",
    "\n",
    "### CUSTOMER QUESTION (Question) ###\n",
    "{question}\n",
    "\n",
    "---\n",
    "### RESPONSE ###\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    " \n",
    "\n",
    "# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Chain (RAG Chain)\n",
    "# ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏ó‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        context=retriever,\n",
    "        question=RunnablePassthrough()\n",
    "    )\n",
    "    | prompt\n",
    "    | typhoon_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 5. ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡πà‡∏≤‡∏ô Chain\n",
    "print(\"\\n--- ü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö (RAG) ---\")\n",
    "question_to_ask = \"‡∏°‡∏µ‡πÄ‡∏ß‡∏¥‡∏Ñ‡∏ä‡πâ‡∏≠‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ç‡∏≤‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏á\"\n",
    "answer = rag_chain.invoke(question_to_ask)\n",
    "\n",
    "print(f\"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question_to_ask}\")\n",
    "print(f\"‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2cde7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36618c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06f91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data ingestion...\n"
     ]
    }
   ],
   "source": [
    "from src.components.ingestion import DataIngestionPipeline \n",
    "\n",
    "# # 1. ‡∏£‡∏±‡∏ô Data Ingestion Pipeline\n",
    "print(\"Starting data ingestion...\")\n",
    "ingestion = DataIngestionPipeline(model_config_path=\"configs/model_config.yaml\", environment_config_path=\"config.yaml\")\n",
    "# vectorstore = ingestion.get_or_create_vectorstore( \n",
    "#     use_semantic_chunking=True,   \n",
    "# ) \n",
    "# # 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ RAG Chain\n",
    "# print(\"Setting up RAG chain...\")\n",
    "# rag_chain = RAGChain()\n",
    "\n",
    "# # ‡πÇ‡∏´‡∏•‡∏î index ‡πÅ‡∏•‡∏∞ texts ‡∏à‡∏≤‡∏Å ingestion\n",
    "# rag_chain.load_index_and_texts(texts=result[\"texts\"])\n",
    "\n",
    "# # ‡∏™‡∏£‡πâ‡∏≤‡∏á chain\n",
    "# rag_chain.initialize_chain()\n",
    "\n",
    "# # 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö query\n",
    "# while True:\n",
    "#     query = input(\"\\nEnter your query (or 'exit' to quit): \")\n",
    "#     if query.lower() == \"exit\":\n",
    "#         break\n",
    "        \n",
    "#     # ‡∏™‡πà‡∏á query ‡πÑ‡∏õ‡∏¢‡∏±‡∏á RAG chain\n",
    "#     response = rag_chain.query(query)\n",
    "    \n",
    "#     # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "#     print(\"\\nResponse:\")\n",
    "#     print(response[\"answer\"])\n",
    "    \n",
    "#     # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (optional)\n",
    "#     print(\"\\nRetrieved documents:\")\n",
    "#     for i, doc in enumerate(response[\"context\"]):\n",
    "#         print(f\"\\nDocument {i+1}:\")\n",
    "#         print(f\"Content: {doc.page_content[:100]}...\")\n",
    "#         print(f\"Score: {doc.metadata.get('score', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a06144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
